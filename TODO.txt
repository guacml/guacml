Bugs:
- Disk caching seems broken

General:
- split out holdout target values before preprocessing pipeline to avoid accidental data leaks
- xg boost said it's only a single thread version. Instructions in doc/build.md
- rename GuacMl to Guac
- replace label encoder with pandas categoricals
(- use single type "numeric" for ints and floats) (have doubts about this DT)
- fix column analyzer to re-run analysis if column dtype has changed (e.g. categorical converts to strings)
- don't mutate df in Dataset.from_df (exclude_cols)

Timeseries:
- solve problem of predicting far in the future. missing median values.

Refactoring:
- re-organize module structure

Disk Caching:
- Would be great to be able to store some hyper parameter optimization iterations
 to disk and later add more. But it's not straightforward, as we have two steps of
 hyper parameter optimization. One before and one after feature selection.
 We could also make the features part of the hyperparamters and then only
 do one big hyper parameter optimization. But the implications are hard to foresee.
- cache `data` directory shouldn't be persisted across test runs

Ideas:
- bundle trained xgboost as a dockerized web service (xgboost4j)
